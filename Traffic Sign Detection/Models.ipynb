{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_xH5RmU9su9W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as td\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "import time\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o01h9AVJdAur",
        "outputId": "b17101d8-5da1-4239-8798-6c12a9d9c6a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEZ-iCxjdDJf",
        "outputId": "18f7dc57-e5cb-4bbb-b7e9-d0089e4e9c5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Indian Traffic Signs Prediction(85 classes)', 'Persian Traffic Sign Dataset (PTSD)', 'Traffic Signs (GTSRB plus 162 custom classes)']\n"
          ]
        }
      ],
      "source": [
        "path='/content/drive/My Drive/6721 Project dataset/'\n",
        "print(os.listdir(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ud-55TXwjopF"
      },
      "outputs": [],
      "source": [
        "path_dataset1 = path+\"/Indian Traffic Signs Prediction(85 classes)/\"\n",
        "path_dataset2 = path+\"/Persian Traffic Sign Dataset (PTSD)/\"\n",
        "path_dataset3 = path+\"/Traffic Signs (GTSRB plus 162 custom classes)/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOYP1i7G-HCb"
      },
      "source": [
        "Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkEmNBhn-K7v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1WRPcW3-K4P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0Xt8GP7-KmT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbmXHVFl-LrR"
      },
      "source": [
        "Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nAjOrIQaaACu"
      },
      "outputs": [],
      "source": [
        "def load_data(path_train, val_split, path_test, batch_size, input_size):\n",
        "  \n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    transform_train= transforms.Compose([transforms.Resize(input_size),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          #transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          normalize\n",
        "                                          ])\n",
        "\n",
        "    transform_test = transforms.Compose([transforms.Resize(input_size),\n",
        "                                         transforms.ToTensor(), \n",
        "                                         normalize])\n",
        "\n",
        "    data_train = datasets.ImageFolder(root=path_train, transform=transform_train)\n",
        "    data_test = datasets.ImageFolder(root=path_test, transform=transform_test)\n",
        "    \n",
        "    val_size = int(len(data_train)*val_split)\n",
        "    train_size = len(data_train) - val_size\n",
        "\n",
        "    train_dataset, val_dataset = td.random_split(data_train, [train_size, val_size])\n",
        "    \n",
        "    data_loader_train = td.DataLoader(train_dataset,\n",
        "                                      batch_size=batch_size,\n",
        "                                      shuffle=True,\n",
        "                                      drop_last=False,\n",
        "                                      num_workers=0,       \n",
        "                                      pin_memory=True) \n",
        "     \n",
        "    data_loader_val = td.DataLoader(val_dataset,\n",
        "                                    batch_size=batch_size,\n",
        "                                    shuffle=True,\n",
        "                                    drop_last=False,\n",
        "                                    num_workers=0)  \n",
        "      \n",
        "    data_loader_test = td.DataLoader(data_test,\n",
        "                                   batch_size=batch_size,\n",
        "                                   shuffle=True,\n",
        "                                   drop_last=False,\n",
        "                                   num_workers=0)\n",
        "    \n",
        "    return data_loader_train, data_loader_test, data_loader_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiuCy21jULAc"
      },
      "source": [
        "#AlexNet "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4le8mbANULAd"
      },
      "outputs": [],
      "source": [
        "nclasses=15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6Zi-J-pULAf",
        "outputId": "0aa882b2-4192-40d4-aa7b-ac5f3b6d5325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.6.0\" to /root/.cache/torch/hub/v0.6.0.zip\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet',pretrained=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DVZimtALULAg"
      },
      "outputs": [],
      "source": [
        "prev_out = AlexNet_model.classifier[4].out_features\n",
        "AlexNet_model.classifier[6] = nn.Linear( prev_out, nclasses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AlexNet_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0ewOVkxVblr",
        "outputId": "342dc0b2-a6e0-41ac-9319-edfe771744a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=15, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(AlexNet_model.parameters(), lr=learning_rate) "
      ],
      "metadata": {
        "id": "vpqeIzg0Vgti"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_train = path_dataset1+\"train\"\n",
        "path_test = path_dataset1+\"test\"\n",
        "val_split = 0.2\n",
        "batch_size = 32\n",
        "input_size = (256,256)\n",
        "\n",
        "train_loader, test_loader, val_loader = load_data(path_train, val_split, path_test, batch_size, input_size)\n",
        "print(len(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MDNL5F0Vmbt",
        "outputId": "2ae5edc1-3f83-4c48-dfcd-aee76d70e6cc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Following training loop has been run for 1 epoch alone for testing the implementation"
      ],
      "metadata": {
        "id": "rV9SvZ4VfXsj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: {}\".format(device))\n",
        "AlexNet_model.to(device)\n",
        "\n",
        "num_epochs = 1\n",
        "total_steps = len(train_loader)\n",
        "t1 = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(train_loader):\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # Forward pass\n",
        "        outputs = AlexNet_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backprop and optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Train accuracy\n",
        "        total = labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
        "                    (correct / total) * 100))\n",
        "            \n",
        "print(\"######## Training Finished in {} seconds ###########\".format(time.time()-t1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvVa2E08Vz5_",
        "outputId": "3c272db0-905b-489e-cab5-8f5039a73d52"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "Epoch [1/1], Step [10/66], Loss: 2.0049, Accuracy: 31.25%\n",
            "Epoch [1/1], Step [20/66], Loss: 2.0597, Accuracy: 25.00%\n",
            "Epoch [1/1], Step [30/66], Loss: 2.2292, Accuracy: 18.75%\n",
            "Epoch [1/1], Step [40/66], Loss: 1.9473, Accuracy: 31.25%\n",
            "Epoch [1/1], Step [50/66], Loss: 1.8179, Accuracy: 25.00%\n",
            "Epoch [1/1], Step [60/66], Loss: 2.0756, Accuracy: 21.88%\n",
            "######## Training Finished in 379.0460522174835 seconds ###########\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AlexNet_model.eval() \n",
        "\n",
        "with torch.no_grad(): \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = AlexNet_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print('Test Accuracy of the model on the {} test images: {} %'\n",
        "        .format(total, (correct / total) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eL9QVbjgDq6",
        "outputId": "f4f4241c-0c0f-4e1d-99e5-97403bd1090f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 710 test images: 34.36619718309859 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}